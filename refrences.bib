
@incollection{rec_prov,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{RecProv}: {Towards} {Provenance}-{Aware} {User} {Space} {Record} and {Replay}},
	copyright = {©2016 Springer International Publishing Switzerland},
	isbn = {978-3-319-40592-6 978-3-319-40593-3},
	shorttitle = {{RecProv}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-40593-3_1},
	abstract = {Deterministic record and replay systems have widely been used in software debugging, failure diagnosis, and intrusion detection. In order to detect the Advanced Persistent Threat (APT), online execution needs to be recorded with acceptable runtime overhead; then, investigators can analyze the replayed execution with heavy dynamic instrumentation. While most record and replay systems rely on kernel module or OS virtualization, those running at user space are favoured for being lighter weight and more portable without any of the changes needed for OS/Kernel virtualization. On the other hand, higher level provenance data at a higher level provides dynamic analysis with system causalities and hugely increases its efficiency. Considering both benefits, we propose a provenance-aware user space record and replay system, called RecProv. RecProv is designed to provide high provenance fidelity; specifically, with versioning files from the recorded trace logs and integrity protection to provenance data through real-time trace isolation. The collected provenance provides the high-level system dependency that helps pinpoint suspicious activities where further analysis can be applied. We show that RecProv is able to output accurate provenance in both visualized graph and W3C standardized PROV-JSON formats.},
	language = {en},
	number = {9672},
	urldate = {2016-09-15},
	booktitle = {Provenance and {Annotation} of {Data} and {Processes}},
	publisher = {Springer International Publishing},
	author = {Ji, Yang and Lee, Sangho and Lee, Wenke},
	editor = {Mattoso, Marta and Glavic, Boris},
	month = jun,
	year = {2016},
	note = {DOI: 10.1007/978-3-319-40593-3\_1},
	keywords = {Artificial Intelligence (incl. Robotics), Computers and Society, Database Management, Information Storage and Retrieval, Information Systems Applications (incl. Internet), Management of Computing and Information Systems, PROV, Provenance capturing, Record and replay, User space},
	pages = {3--15},
	file = {Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/J8CIFBDR/10.html:text/html}
}

@inproceedings{conf/sdm/LeFevreT10,
  added-at = {2014-02-12T00:00:00.000+0100},
  author = {LeFevre, Kristen and Terzi, Evimaria},
  biburl = {https://www.bibsonomy.org/bibtex/2c129e283e1ec68ea3bb4826fb4d84f19/dblp},
  booktitle = {SDM},
  crossref = {conf/sdm/2010},
  ee = {http://dx.doi.org/10.1137/1.9781611972801.40},
  interhash = {7cd825d3e72776fc8b79b4c15427323b},
  intrahash = {c129e283e1ec68ea3bb4826fb4d84f19},
  isbn = {978-1-61197-280-1},
  keywords = {dblp},
  pages = {454-465},
  publisher = {SIAM},
  timestamp = {2015-06-19T08:53:25.000+0200},
  title = {GraSS: Graph Structure Summarization.},
  url = {http://dblp.uni-trier.de/db/conf/sdm/sdm2010.html#LeFevreT10},
  year = 2010
}



@inbook{grass,
author = {Kristen LeFevre and Evimaria Terzi},
title = {GraSS: Graph Structure Summarization},
booktitle = {Proceedings of the 2010 SIAM International Conference on Data Mining},
chapter = {},
pages = {454-465},
doi = {10.1137/1.9781611972801.40},
URL = {http://epubs.siam.org/doi/abs/10.1137/1.9781611972801.40},
eprint = {http://epubs.siam.org/doi/pdf/10.1137/1.9781611972801.40}
}

@inproceedings{compressing_graph,
 author = {Adler, Micah and Mitzenmacher, Michael},
 title = {Towards Compressing Web Graphs},
 booktitle = {Proceedings of the Data Compression Conference},
 series = {DCC '01},
 year = {2001},
 pages = {203--},
 url = {http://dl.acm.org/citation.cfm?id=882454.875027},
 acmid = {875027},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA}
} 

@inproceedings{Tian,
 author = {Tian, Yuanyuan and Hankins, Richard A. and Patel, Jignesh M.},
 title = {Efficient Aggregation for Graph Summarization},
 booktitle = {Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '08},
 year = {2008},
 isbn = {978-1-60558-102-6},
 location = {Vancouver, Canada},
 pages = {567--580},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/1376616.1376675},
 doi = {10.1145/1376616.1376675},
 acmid = {1376675},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {aggregation, graphs, social networks, summarization}
} 


@inproceedings{chimera,
 author = {Foster, Ian T. and V\"{o}ckler, Jens-S. and Wilde, Michael and Zhao, Yong},
 title = {Chimera: AVirtual Data System for Representing, Querying, and Automating Data Derivation},
 booktitle = {Proceedings of the 14th International Conference on Scientific and Statistical Database Management},
 series = {SSDBM '02},
 year = {2002},
 isbn = {0-7695-1632-7},
 pages = {37--46},
 numpages = {10},
 url = {http://dx.doi.org/10.1109/SSDM.2002.1029704},
 doi = {10.1109/SSDM.2002.1029704},
 acmid = {695938},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

@misc{prov_dm,
	title = {{PROV}-{DM}: {The} {PROV} {Data} {Model}},
	url = {https://www.w3.org/TR/prov-dm/},
	urldate = {2016-09-15},
	file = {PROV-DM\: The PROV Data Model:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/WPH6IJXZ/prov-dm.html:text/html},
	note = {Accessed: 2016-10-01},
	howpublished = {\url{https://www.w3.org/TR/prov-dm/}}
}

@misc {prov_json,
    title       = {{PROV}-{JSON}: {The} {PROV} {Data} {Model}},
    institution = {W3C},
    year        = {2013},
    month       = {Apr},
    howpublished = {\url{http://www.w3.org/Submission/2013/SUBM-prov-json-20130424}},
    note = {Accessed: 2016-10-01}
}

@inproceedings{park_provenance-based_2012,
	title = {A provenance-based access control model},
	doi = {10.1109/PST.2012.6297930},
	abstract = {Existence of data provenance information in a system raises at least two security-related issues. One is how provenance data can be used to enhance security in the system and the other is how to protect provenance data which might be more sensitive than the data itself. Recent data provenance-related access control literature mainly focuses on the latter issue of protecting provenance data. In this paper, we propose a novel provenance-based access control model that addresses the former objective. Using provenance data for access control to the underlying data facilitates additional capabilities beyond those available in traditional access control models. We utilize a notion of dependency as the key foundation for access control policy specification. Dependency-based policy provides simplicity and effectiveness in policy specification and access control administration. We show our model can support dynamic separation of duty, workflow control, origin-based control, and object versioning. The proposed model identifies essential components and concepts and provides a foundational base model for provenance-based access control. We further discuss possible extensions of the proposed base model for enhanced access controls.},
	booktitle = {2012 {Tenth} {Annual} {International} {Conference} on {Privacy}, {Security} and {Trust} ({PST})},
	author = {Park, J. and Nguyen, D. and Sandhu, R.},
	month = jul,
	year = {2012},
	keywords = {access control administration, access control policy specification, authorisation, Authorization, Computational modeling, Data models, data provenance information, dependency-based policy, dependency notion, dynamic duty separation, Grammar, History, information science, object versioning, origin-based control, provenance-based access control model, provenance data protection, security enhancement, workflow control},
	pages = {137--144},
	file = {IEEE Xplore Abstract Record:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/5R5269ZN/6297930.html:text/html}
}

@inproceedings{ledlie_provenance-aware_2005,
	title = {Provenance-{Aware} {Sensor} {Data} {Storage}},
	doi = {10.1109/ICDE.2005.270},
	abstract = {Sensor network data has both historical and realtime value. Making historical sensor data useful, in particular, requires storage, naming, and indexing. Sensor data presents new challenges in these areas. Such data is location-specific but also distributed; it is collected in a particular physical location and may be most useful there, but it has additional value when combined with other sensor data collections in a larger distributed system. Thus, arranging location-sensitive peer-to-peer storage is one challenge. Sensor data sets do not have obvious names, so naming them in a globally useful fashion is another challenge. The last challenge arises from the need to index these sensor data sets to make them searchable. The key to sensor data identity is provenance, the full history or lineage of the data. We show how provenance addresses the naming and indexing issues and then present a research agenda for constructing distributed, indexed repositories of sensor data.},
	booktitle = {21st {International} {Conference} on {Data} {Engineering} {Workshops} ({ICDEW}'05)},
	author = {Ledlie, J. and Ng, Chaki and Holland, D. A.},
	month = apr,
	year = {2005},
	keywords = {Biosensors, Data engineering, History, Indexing, Memory, Monitoring, Peer to peer computing, Sensor phenomena and characterization, Sensor systems, Telecommunication traffic},
	pages = {1189--1189},
	file = {IEEE Xplore Abstract Record:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/78NNNMZW/1647801.html:text/html}
}


@article{seltzer_collecting_2011,
	title = {Collecting {Provenance} via the {Xen} {Hypervisor}},
	copyright = {open},
	url = {https://dash.harvard.edu/handle/1/5168855},
	abstract = {The Provenance Aware Storage Systems project (PASS) currently collects system-level provenance by intercepting system calls in the Linux kernel and storing the provenance in a stackable ﬁlesystem. While this approach is reasonably efﬁcient, it suffers from two signiﬁcant drawbacks: each new revision of the kernel requires reintegration of PASS changes, the stability of which must be continually tested; also, the use of a stackable ﬁlesystem makes it difﬁcult to collect provenance
on root volumes, especially during early boot. In this paper we describe an approach to collecting system-level provenance from virtual guest machines running under the Xen hypervisor. We make the case that our approach alleviates the aforementioned difﬁculties and promotes adoption of provenance collection within cloud computing platforms.},
	language = {en\_US},
	urldate = {2016-09-15},
	author = {Seltzer, Margo I. and Macko, Peter and Chiarini, Marc A.},
	year = {2011},
	file = {Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/G8GBG7UC/Seltzer et al. - 2011 - Collecting Provenance via the Xen Hypervisor.pdf:application/pdf;Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/RRHHDJVR/5168855.html:text/html}
}



@inproceedings{bates_trustworthy_2015,
  title={Trustworthy whole-system provenance for the Linux kernel},
  author={Bates, Adam and Tian, Dave Jing and Butler, Kevin RB and Moyer, Thomas},
  booktitle={24th USENIX Security Symposium (USENIX Security 15)},
  pages={319--334},
  year={2015}
}



@inproceedings{hi_fi,
	address = {New York, NY, USA},
	series = {{ACSAC} '12},
	title = {Hi-{Fi}: {Collecting} {High}-fidelity {Whole}-system {Provenance}},
	isbn = {978-1-4503-1312-4},
	shorttitle = {Hi-{Fi}},
	url = {http://doi.acm.org/10.1145/2420950.2420989},
	doi = {10.1145/2420950.2420989},
	abstract = {Data provenance---a record of the origin and evolution of data in a system---is a useful tool for forensic analysis. However, existing provenance collection mechanisms fail to achieve sufficient breadth or fidelity to provide a holistic view of a system's operation over time. We present Hi-Fi, a kernel-level provenance system which leverages the Linux Security Modules framework to collect high-fidelity whole-system provenance. We demonstrate that Hi-Fi is able to record a variety of malicious behavior within a compromised system. In addition, our benchmarks show the collection overhead from Hi-Fi to be less than 1\% for most system calls and 3\% in a representative workload, while simultaneously generating a system measurement that fully reflects system evolution. In this way, we show that we can collect broad, high-fidelity provenance data which is capable of supporting detailed forensic analysis.},
	urldate = {2016-09-15},
	booktitle = {Proceedings of the 28th {Annual} {Computer} {Security} {Applications} {Conference}},
	publisher = {ACM},
	author = {Pohly, Devin J. and McLaughlin, Stephen and McDaniel, Patrick and Butler, Kevin},
	year = {2012},
	keywords = {data provenance, forensics, malware, reference monitor},
	pages = {259--268}
	
	
}

@incollection{gessiou_towards_2012,
	series = {{IFIP} {Advances} in {Information} and {Communication} {Technology}},
	title = {Towards a {Universal} {Data} {Provenance} {Framework} {Using} {Dynamic} {Instrumentation}},
	copyright = {©2012 IFIP International Federation for Information Processing},
	isbn = {978-3-642-30435-4 978-3-642-30436-1},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-30436-1_9},
	abstract = {The advantage of collecting data provenance information has driven research on how to extend or modify applications and systems in order to provide it, or the creation of architectures that are built from the ground up with provenance capabilities. In this paper we propose a universal data provenance framework, using dynamic instrumentation, which gathers data provenance information for real-world applications without any code modifications. Our framework simplifies the task of finding the right points to instrument, which can be cumbersome in large and complex systems. We have built a proof-of-concept implementation of the framework on top of DTrace. Moreover, we evaluated its functionality by using it for three different scenarios: file-system operations, database transactions and web browser HTTP requests. Based on our experiences we believe that it is possible to provide data provenance, transparently, to any layer of the software stack.},
	language = {en},
	number = {376},
	urldate = {2016-09-15},
	booktitle = {Information {Security} and {Privacy} {Research}},
	publisher = {Springer Berlin Heidelberg},
	author = {Gessiou, Eleni and Pappas, Vasilis and Athanasopoulos, Elias and Keromytis, Angelos D. and Ioannidis, Sotiris},
	editor = {Gritzalis, Dimitris and Furnell, Steven and Theoharidou, Marianthi},
	month = jun,
	year = {2012},
	note = {DOI: 10.1007/978-3-642-30436-1\_9},
	keywords = {Algorithm Analysis and Problem Complexity, Computer Communication Networks, Computers and Society, Data Encryption, Information Systems Applications (incl. Internet), Management of Computing and Information Systems},
	pages = {103--114},
	file = {Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/F92G29MF/Gessiou et al. - 2012 - Towards a Universal Data Provenance Framework Usin.pdf:application/pdf;Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/2HF79I6R/978-3-642-30436-1_9.html:text/html}
}

@inproceedings{story,
	address = {Berkeley, CA, USA},
	series = {{TAPP}'09},
	title = {Story {Book}: {An} {Efficient} {Extensible} {Provenance} {Framework}},
	shorttitle = {Story {Book}},
	url = {http://dl.acm.org/citation.cfm?id=1525932.1525943},
	abstract = {Most application provenance systems are hard coded for a particular type of system or data, while current provenance file systems maintain in-memory provenance graphs and reside in kernel space, leading to complex and constrained implementations. Story Book resides in user space, and treats provenance events as a generic event log, leading to a simple, flexible and easily optimized system. We demonstrate the flexibility of our design by adding provenance to a number of different systems, including a file system, database and a number of file types, and by implementing two separate storage backends. Although Story Book is nearly 2.5 times slower than ext3 under worst case workloads, this is mostly due to FUSE message passing overhead. Our experiments show that coupling our simple design with existing storage optimizations provides higher throughput than existing systems.},
	urldate = {2016-09-15},
	booktitle = {First {Workshop} on  the {Theory} and {Practice} of {Provenance}},
	publisher = {USENIX Association},
	author = {Spillane, R. and Sears, R. and Yalamanchili, C. and Gaikwad, S. and Chinni, M. and Zadok, E.},
	year = {2009},
	pages = {11:1--11:10}
}

@inproceedings{tariq_towards_2012,
	address = {Berkeley, CA, USA},
	series = {{TaPP}'12},
	title = {Towards {Automated} {Collection} of {Application}-level {Data} {Provenance}},
	url = {http://dl.acm.org/citation.cfm?id=2342875.2342891},
	abstract = {Gathering data provenance at the operating system level is useful for capturing system-wide activity. However, many modern programs are complex and can perform numerous tasks concurrently. Capturing their provenance at this level, where processes are treated as single entities, may lead to the loss of useful intra-process detail. This can, in turn, produce false dependencies in the provenance graph. Using the LLVM compiler framework and SPADE provenance infrastructure, we investigate adding provenance instrumentation to allow intraprocess provenance to be captured automatically. This results in a more accurate representation of the provenance relationships and eliminates some false dependencies. Since the capture of fine-grained provenance incurs increased overhead for storage and querying, we minimize the records retained by allowing users to declare aspects of interest and then automatically infer which provenance records are unnecessary and can be discarded.},
	urldate = {2016-09-15},
	booktitle = {Proceedings of the 4th {USENIX} {Conference} on {Theory} and {Practice} of {Provenance}},
	publisher = {USENIX Association},
	author = {Tariq, Dawood and Ali, Maisem and Gehani, Ashish},
	year = {2012},
	pages = {16--16}
}

@inproceedings{ghoshal_provenance_2013,
	address = {New York, NY, USA},
	series = {{EDBT} '13},
	title = {Provenance from {Log} {Files}: {A} {BigData} {Problem}},
	isbn = {978-1-4503-1599-9},
	shorttitle = {Provenance from {Log} {Files}},
	url = {http://doi.acm.org/10.1145/2457317.2457366},
	doi = {10.1145/2457317.2457366},
	urldate = {2016-09-15},
	booktitle = {Proceedings of the {Joint} {EDBT}/{ICDT} 2013 {Workshops}},
	publisher = {ACM},
	author = {Ghoshal, Devarshi and Plale, Beth},
	year = {2013},
	pages = {290--297}
}

@inproceedings{Navlakha,
 author = {Navlakha, Saket and Rastogi, Rajeev and Shrivastava, Nisheeth},
 title = {Graph Summarization with Bounded Error},
 booktitle = {Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '08},
 year = {2008},
 isbn = {978-1-60558-102-6},
 location = {Vancouver, Canada},
 pages = {419--432},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/1376616.1376661},
 doi = {10.1145/1376616.1376661},
 acmid = {1376661},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {approximation, graph compression, minimum description length},
} 

@article{hussain_secure_2014,
	title = {Secure {Data} {Provenance} {Compression} {Using} {Arithmetic} {Coding} in {Wireless} {Sensor} {Networks}},
	url = {http://docs.lib.purdue.edu/ccpubs/645},
	doi = {10.1109/PCCC.2014.7017068},
	journal = {2014 IEEE International Performance Computing and Communications Conference (IPCCC)},
	author = {Hussain, Syed Rafiul and Wang, Changda and Sultana, Salmin and Bertino, Elisa},
	month = dec,
	year = {2014},
	file = {"Secure Data Provenance Compression Using Arithmetic Coding in Wireless" by Syed Rafiul Hussain, Changda Wang et al.:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/PD6237WV/645.html:text/html}
}

@inproceedings{muniswamy_reddy,
	address = {Berkeley, CA, USA},
	series = {{ATEC} '06},
	title = {Provenance-aware {Storage} {Systems}},
	url = {http://dl.acm.org/citation.cfm?id=1267359.1267363},
	abstract = {A Provenance-Aware Storage System (PASS) is a storage system that automatically collects and maintains provenance or lineage, the complete history or ancestry of an item. We discuss the advantages of treating provenance as meta-data collected and maintained by the storage system, rather than as manual annotations stored in a separately administered database. We describe a PASS implementation, discussing the challenges it presents, performance cost it incurs, and the new functionality it enables. We show that with reasonable overhead, we can provide useful functionality not available in today's file systems or provenance management systems.},
	urldate = {2016-09-16},
	booktitle = {Proceedings of the {Annual} {Conference} on {USENIX} '06 {Annual} {Technical} {Conference}},
	publisher = {USENIX Association},
	author = {Muniswamy-Reddy, Kiran-Kumar and Holland, David A. and Braun, Uri and Seltzer, Margo},
	year = {2006},
	pages = {4--4}
}

@inproceedings{groth,
	title = {{PReServ}: {Provenance} recording for services},
	shorttitle = {{PReServ}},
	abstract = {The importance of understanding the process by which a result was generated in an experiment is fundamental to science. Without such information, other scientists cannot replicate, validate, or duplicate an experiment. We define provenance as the process that led to a result. With large scale in-silico experiments, it becomes increasingly difficult for scientists to record process documentation that can be used to retrieve the provenance of a result. Provenance Recording for Services (PReServ) is a software package that allows developers to integrate process documentation recording into their applications. PReServ has been used by several applications and its performance has been benchmarked. 1},
	booktitle = {In, UK e-Science All Hands Meeting 2005, Nottingham, UK, EPSRC},
	author = {Groth, Paul and Miles, Simon and Moreau, Luc},
	file = {Citeseer - Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/FE2DFP4Z/Groth et al. - PReServ Provenance recording for services.pdf:application/pdf;Citeseer - Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/JUTMJJST/summary.html:text/html},	
date ={2005}
}

@article{cheney_provenance_2009,
	title = {Provenance in {Databases}: {Why}, {How}, and {Where}},
	volume = {1},
	issn = {1931-7883},
	shorttitle = {Provenance in {Databases}},
	url = {http://dx.doi.org/10.1561/1900000006},
	doi = {10.1561/1900000006},
	abstract = {Different notions of provenance for database queries have been proposed and studied in the past few years. In this article, we detail three main notions of database provenance, some of their applications, and compare and contrast amongst them. Specifically, we review why, how, and where provenance, describe the relationships among these notions of provenance, and describe some of their applications in confidence computation, view maintenance and update, debugging, and annotation propagation.},
	number = {4},
	urldate = {2016-09-16},
	journal = {Found. Trends databases},
	author = {Cheney, James and Chiticariu, Laura and Tan, Wang-Chiew},
	month = apr,
	year = {2009},
	pages = {379--474}
}

@inproceedings{muniswamy_reddy_provenance_2010,
	address = {Berkeley, CA, USA},
	series = {{FAST}'10},
	title = {Provenance for the {Cloud}},
	url = {http://dl.acm.org/citation.cfm?id=1855511.1855526},
	abstract = {The cloud is poised to become the next computing environment for both data storage and computation due to its pay-as-you-go and provision-as-you-go models. Cloud storage is already being used to back up desktop user data, host shared scientific data, store web application data, and to serve web pages. Today's cloud stores, however, are missing an important ingredient: provenance. Provenance is metadata that describes the history of an object. We make the case that provenance is crucial for data stored on the cloud and identify the properties of provenance that enable its utility. We then examine current cloud offerings and design and implement three protocols for maintaining data/provenance in current cloud stores. The protocols represent different points in the design space and satisfy different subsets of the provenance properties. Our evaluation indicates that the overheads of all three protocols are comparable to each other and reasonable in absolute terms. Thus, one can select a protocol based upon the properties it provides without sacrificing performance. While it is feasible to provide provenance as a layer on top of today's cloud offerings, we conclude by presenting the case for incorporating provenance as a core cloud feature, discussing the issues in doing so.},
	urldate = {2016-09-16},
	booktitle = {Proceedings of the 8th {USENIX} {Conference} on {File} and {Storage} {Technologies}},
	publisher = {USENIX Association},
	author = {Muniswamy-Reddy, Kiran-Kumar and Macko, Peter and Seltzer, Margo},
	year = {2010},
	pages = {15--14}
}

@incollection{glavic_case_2011,
	title = {The {Case} for {Fine}-{Grained} {Stream} {Provenance}},
	url = {http://cs.iit.edu/%7edbgroup/pdfpubls/GE11.pdf},
	booktitle = {Proceedings of the 1st {Workshop} on {Data} {Streams} and {Event} {Processing} ({DSEP}) collocated with {BTW}},
	author = {Glavic, Boris and Esmaili, Kyumars Sheykh and Fischer, Peter M. and Tatbul, Nesime},
	year = {2011}
}

@article{atzori_internet_2010,
	title = {The {Internet} of {Things}: {A} survey},
	volume = {54},
	issn = {1389-1286},
	shorttitle = {The {Internet} of {Things}},
	url = {http://www.sciencedirect.com/science/article/pii/S1389128610001568},
	doi = {10.1016/j.comnet.2010.05.010},
	abstract = {This paper addresses the Internet of Things. Main enabling factor of this promising paradigm is the integration of several technologies and communications solutions. Identification and tracking technologies, wired and wireless sensor and actuator networks, enhanced communication protocols (shared with the Next Generation Internet), and distributed intelligence for smart objects are just the most relevant. As one can easily imagine, any serious contribution to the advance of the Internet of Things must necessarily be the result of synergetic activities conducted in different fields of knowledge, such as telecommunications, informatics, electronics and social science. In such a complex scenario, this survey is directed to those who want to approach this complex discipline and contribute to its development. Different visions of this Internet of Things paradigm are reported and enabling technologies reviewed. What emerges is that still major issues shall be faced by the research community. The most relevant among them are addressed in details.},
	number = {15},
	urldate = {2016-09-18},
	journal = {Computer Networks},
	author = {Atzori, Luigi and Iera, Antonio and Morabito, Giacomo},
	month = oct,
	year = {2010},
	keywords = {Internet of Things, Pervasive computing, RFID systems},
	pages = {2787--2805},
	file = {ScienceDirect Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/I2WG2N2Q/S1389128610001568.html:text/html}
}

@misc{xacml,
	title = {{eXtensible} {Access} {Control} {Markup} {Language} ({XACML}) {Version} 3.0},
	url = {http://docs.oasis-open.org/xacml/3.0/xacml-3.0-core-spec-os-en.html},
	urldate = {2016-09-18},
	file = {eXtensible Access Control Markup Language (XACML) Version 3.0:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/E4SCC524/xacml-3.0-core-spec-os-en.html:text/html},
	 note = {Accessed: 2016-10-01},
	howpublished = {\url{http://docs.oasis-open.org/xacml/3.0/xacml-3.0-core-spec-os-en.html}}
	
}

@article{gubbi_internet_2013,
	series = {Including {Special} sections: {Cyber}-enabled {Distributed} {Computing} for {Ubiquitous} {Cloud} and {Network} {Services} \& {Cloud} {Computing} and {Scientific} {Applications} — {Big} {Data}, {Scalable} {Analytics}, and {Beyond}},
	title = {Internet of {Things} ({IoT}): {A} vision, architectural elements, and future directions},
	volume = {29},
	issn = {0167-739X},
	shorttitle = {Internet of {Things} ({IoT})},
	url = {http://www.sciencedirect.com/science/article/pii/S0167739X13000241},
	doi = {10.1016/j.future.2013.01.010},
	abstract = {Ubiquitous sensing enabled by Wireless Sensor Network (WSN) technologies cuts across many areas of modern day living. This offers the ability to measure, infer and understand environmental indicators, from delicate ecologies and natural resources to urban environments. The proliferation of these devices in a communicating–actuating network creates the Internet of Things (IoT), wherein sensors and actuators blend seamlessly with the environment around us, and the information is shared across platforms in order to develop a common operating picture (COP). Fueled by the recent adaptation of a variety of enabling wireless technologies such as RFID tags and embedded sensor and actuator nodes, the IoT has stepped out of its infancy and is the next revolutionary technology in transforming the Internet into a fully integrated Future Internet. As we move from www (static pages web) to web2 (social networking web) to web3 (ubiquitous computing web), the need for data-on-demand using sophisticated intuitive queries increases significantly. This paper presents a Cloud centric vision for worldwide implementation of Internet of Things. The key enabling technologies and application domains that are likely to drive IoT research in the near future are discussed. A Cloud implementation using Aneka, which is based on interaction of private and public Clouds is presented. We conclude our IoT vision by expanding on the need for convergence of WSN, the Internet and distributed computing directed at technological research community.},
	number = {7},
	urldate = {2016-09-18},
	journal = {Future Generation Computer Systems},
	author = {Gubbi, Jayavardhana and Buyya, Rajkumar and Marusic, Slaven and Palaniswami, Marimuthu},
	month = sep,
	year = {2013},
	keywords = {Cloud computing, Internet of Things, RFID, Smart environments, Ubiquitous sensing, Wireless sensor networks},
	pages = {1645--1660},
	file = {ScienceDirect Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/8KAG8GGC/Gubbi et al. - 2013 - Internet of Things (IoT) A vision, architectural .pdf:application/pdf;ScienceDirect Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/VCPHTHW7/S0167739X13000241.html:text/html}
}

@inproceedings{bates_towards_2013,
	address = {New York, NY, USA},
	series = {{CODASPY} '13},
	title = {Towards {Secure} {Provenance}-based {Access} {Control} in {Cloud} {Environments}},
	isbn = {978-1-4503-1890-7},
	url = {http://doi.acm.org/10.1145/2435349.2435389},
	doi = {10.1145/2435349.2435389},
	abstract = {As organizations become increasingly reliant on cloud computing for servicing their data storage requirements, the need to govern access control at finer granularities becomes particularly important. This challenge is increased by the lack of policy supporting data migration across geographic boundaries and through organizations with divergent regulatory policies. In this paper, we present an architecture for secure and distributed management of provenance, enabling its use in security-critical applications. Provenance, a metadata history detailing the derivation of an object, contains information that allows for expressive, policy-independent access control decisions. We consider how to manage and validate the metadata of a provenance-aware cloud system, and introduce protocols that allow for secure transfer of provenance metadata between end hosts and cloud authorities. Using these protocols, we develop a provenance-based access control mechanism for Cumulus cloud storage, capable of processing thousands of operations per second on a single deployment. Through the introduction of replicated components, we achieve overhead costs of just 14\%, demonstrating that provenance-based access control is a practical and scalable solution for the cloud.},
	urldate = {2016-09-19},
	booktitle = {Proceedings of the {Third} {ACM} {Conference} on {Data} and {Application} {Security} and {Privacy}},
	publisher = {ACM},
	author = {Bates, Adam and Mood, Ben and Valafar, Masoud and Butler, Kevin},
	year = {2013},
	keywords = {access control, provenance, secure storage},
	pages = {277--284}
}

@inproceedings{ma_access_2016,
	title = {Access control management with provenance in healthcare environments},
	doi = {10.1109/CSCWD.2016.7566048},
	abstract = {Provenance, describes how a data item came to be its current state. A Directed Acyclic Graph, nature of the provenance poses challenges to access control models and querying languages. Access control policies are needed to protect the security of data provenance. In this paper, we apply proposed notions of regular expression for provenance as the structure of a provenance graph is very large. We use an extending access control language for data provenance, and semantic Web technologies to effectively query provenances. Finally, we tailored an access control language by using the regular expressions through a medical example.},
	booktitle = {2016 {IEEE} 20th {International} {Conference} on {Computer} {Supported} {Cooperative} {Work} in {Design} ({CSCWD})},
	author = {Ma, T. and Wang, H. and Cao, J. and Yong, J. and Zhao, Y.},
	month = may,
	year = {2016},
	keywords = {access control, Data models, Diabetes, OPM, Process control, provenance, Resource description framework, Security},
	pages = {545--550},
	file = {IEEE Xplore Abstract Record:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/IKFWPDFF/7566048.html:text/html}
}

@incollection{buneman_why_2001,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Why and {Where}: {A} {Characterization} of {Data} {Provenance}},
	copyright = {©2001 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-41456-8 978-3-540-44503-6},
	shorttitle = {Why and {Where}},
	url = {http://link.springer.com/chapter/10.1007/3-540-44503-X_20},
	abstract = {With the proliferation of database views and curated data- bases, the issue of data provenance - where a piece of data came from and the process by which it arrived in the database - is becoming increasingly important, especially in scientific databases where understanding provenance is crucial to the accuracy and currency of data. In this paper we describe an approach to computing provenance when the data of interest has been created by a database query. We adopt a syntactic approach and present results for a general data model that applies to relational databases as well as to hierarchical data such as XML. A novel aspect of our work is a distinction between “why” provenance (refers to the source data that had some influence on the existence of the data) and “where” provenance (refers to the location(s) in the source databases from which the data was extracted). Supported in part by an Alfred P. Sloan Research Fellowship.},
	language = {en},
	number = {1973},
	urldate = {2016-09-20},
	booktitle = {Database {Theory} — {ICDT} 2001},
	publisher = {Springer Berlin Heidelberg},
	author = {Buneman, Peter and Khanna, Sanjeev and Wang-Chiew, Tan},
	editor = {Bussche, Jan Van den and Vianu, Victor},
	month = jan,
	year = {2001},
	note = {DOI: 10.1007/3-540-44503-X\_20},
	keywords = {Algorithm Analysis and Problem Complexity, Database Management, Data Structures, Cryptology and Information Theory, Information Storage and Retrieval, Information Systems Applications (incl. Internet), Mathematical Logic and Formal Languages},
	pages = {316--330},
	file = {Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/P5VGKUPT/10.html:text/html}
}

@incollection{altintas,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Provenance {Collection} {Support} in the {Kepler} {Scientific} {Workflow} {System}},
	copyright = {©2006 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-46302-3 978-3-540-46303-0},
	url = {http://link.springer.com/chapter/10.1007/11890850_14},
	abstract = {In many data-driven applications, analysis needs to be performed on scientific information obtained from several sources and generated by computations on distributed resources. Systematic analysis of this scientific information unleashes a growing need for automated data-driven applications that also can keep track of the provenance of the data and processes with little user interaction and overhead. Such data analysis can be facilitated by the recent advancements in scientific workflow systems. A major profit when using scientific workflow systems is the ability to make provenance collection a part of the workflow. Specifically, provenance should include not only the standard data lineage information but also information about the context in which the workflow was used, execution that processed the data, and the evolution of the workflow design. In this paper we describe a complete framework for data and process provenance in the Kepler Scientific Workflow System. We outline the requirements and issues related to data and workflow provenance in a multi-disciplinary workflow system and introduce how generic provenance capture can be facilitated in Kepler’s actor-oriented workflow environment. We also describe the usage of the stored provenance information for efficient rerun of scientific workflows.},
	language = {en},
	number = {4145},
	urldate = {2016-09-20},
	booktitle = {Provenance and {Annotation} of {Data}},
	publisher = {Springer Berlin Heidelberg},
	author = {Altintas, Ilkay and Barney, Oscar and Jaeger-Frank, Efrat},
	editor = {Moreau, Luc and Foster, Ian},
	month = may,
	year = {2006},
	note = {DOI: 10.1007/11890850\_14},
	keywords = {Computers and Society, Data Structures, Cryptology and Information Theory, Information Storage and Retrieval, Information Systems Applications (incl. Internet), Management of Computing and Information Systems, Operating Systems},
	pages = {118--132},
	file = {Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/JXQB7DJI/Altintas et al. - 2006 - Provenance Collection Support in the Kepler Scient.pdf:application/pdf;Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/X55G7GPJ/10.html:text/html}
}

@incollection{mattern,
	address = {Berlin, Heidelberg},
	title = {From {Active} {Data} {Management} to {Event}-based {Systems} and {More}},
	isbn = {978-3-642-17225-0},
	url = {http://dl.acm.org/citation.cfm?id=1985625.1985645},
	abstract = {This paper discusses the vision, the challenges, possible usage scenarios and technological building blocks of the "Internet of Things". In particular, we consider RFID and other important technological developments such as IP stacks and web servers for smart everyday objects. The paper concludes with a discussion of social and governance issues that are likely to arise as the vision of the Internet of Things becomes a reality.},
	urldate = {2016-09-20},
	publisher = {Springer-Verlag},
	author = {Mattern, Friedemann and Floerkemeier, Christian},
	editor = {Sachs, Kai and Petrov, Ilia and Guerrero, Pablo},
	year = {2010},
	keywords = {Internet of Things, RFID, smart objects, Wireless sensor networks},
	pages = {242--259}
}

@incollection{mattern_active_2010-1,
	address = {Berlin, Heidelberg},
	title = {From {Active} {Data} {Management} to {Event}-based {Systems} and {More}},
	isbn = {978-3-642-17225-0},
	url = {http://dl.acm.org/citation.cfm?id=1985625.1985645},
	abstract = {This paper discusses the vision, the challenges, possible usage scenarios and technological building blocks of the "Internet of Things". In particular, we consider RFID and other important technological developments such as IP stacks and web servers for smart everyday objects. The paper concludes with a discussion of social and governance issues that are likely to arise as the vision of the Internet of Things becomes a reality.},
	urldate = {2016-09-20},
	publisher = {Springer-Verlag},
	author = {Mattern, Friedemann and Floerkemeier, Christian},
	editor = {Sachs, Kai and Petrov, Ilia and Guerrero, Pablo},
	year = {2010},
	keywords = {Internet of Things, RFID, smart objects, Wireless sensor networks},
	pages = {242--259}
}

@article{moreau_open_2011,
	title = {The {Open} {Provenance} {Model} {Core} {Specification} ({V}1.1)},
	volume = {27},
	issn = {0167-739X},
	url = {http://dx.doi.org/10.1016/j.future.2010.07.005},
	doi = {10.1016/j.future.2010.07.005},
	abstract = {The Open Provenance Model is a model of provenance that is designed to meet the following requirements: (1) Allow provenance information to be exchanged between systems, by means of a compatibility layer based on a shared provenance model. (2) Allow developers to build and share tools that operate on such a provenance model. (3) Define provenance in a precise, technology-agnostic manner. (4) Support a digital representation of provenance for any ''thing'', whether produced by computer systems or not. (5) Allow multiple levels of description to coexist. (6) Define a core set of rules that identify the valid inferences that can be made on provenance representation. This document contains the specification of the Open Provenance Model (v1.1) resulting from a community effort to achieve inter-operability in the Provenance Challenge series.},
	number = {6},
	urldate = {2016-09-20},
	journal = {Future Gener. Comput. Syst.},
	author = {Moreau, Luc and Clifford, Ben and Freire, Juliana and Futrelle, Joe and Gil, Yolanda and Groth, Paul and Kwasnikowska, Natalia and Miles, Simon and Missier, Paolo and Myers, Jim and Plale, Beth and Simmhan, Yogesh and Stephan, Eric and den Bussche, Jan Van},
	month = jun,
	year = {2011},
	keywords = {Inter-operability, provenance, Representation},
	pages = {743--756}
}

@inproceedings{lim,
	address = {New York, NY, USA},
	series = {{DMSN} '10},
	title = {Provenance-based {Trustworthiness} {Assessment} in {Sensor} {Networks}},
	isbn = {978-1-4503-0416-0},
	url = {http://doi.acm.org/10.1145/1858158.1858162},
	doi = {10.1145/1858158.1858162},
	abstract = {As sensor networks are being increasingly deployed in decision-making infrastructures such as battlefield monitoring systems and SCADA (Supervisory Control and Data Acquisition) systems, making decision makers aware of the trustworthiness of the collected data is a crucial. To address this problem, we propose a systematic method for assessing the trustworthiness of data items. Our approach uses the data provenance as well as their values in computing trust scores, that is, quantitative measures of trustworthiness. To obtain trust scores, we propose a cyclic framework which well reflects the inter-dependency property: the trust score of the data affects the trust score of the network nodes that created and manipulated the data, and vice-versa. The trust scores of data items are computed from their value similarity and provenance similarity. The value similarity comes from the principle that "the more similar values for the same event, the higher the trust scores". The provenance similarity is based on the principle that "the more different data provenances with similar values, the higher the trust scores". Experimental results show that our approach provides a practical solution for trustworthiness assessment in sensor networks.},
	urldate = {2016-09-21},
	booktitle = {Proceedings of the {Seventh} {International} {Workshop} on {Data} {Management} for {Sensor} {Networks}},
	publisher = {ACM},
	author = {Lim, Hyo-Sang and Moon, Yang-Sae and Bertino, Elisa},
	year = {2010},
	keywords = {data provenance, sensor network, trustworthiness},
	pages = {2--7}
}

@inproceedings{_general-purpose_2012,
 author = {Macko, Peter and Seltzer, Margo},
 title = {A General-purpose Provenance Library},
 booktitle = {Proceedings of the 4th USENIX Conference on Theory and Practice of Provenance},
 series = {TaPP'12},
 year = {2012},
 location = {Boston, MA},
 pages = {6--6},
 numpages = {1},
 url = {http://dl.acm.org/citation.cfm?id=2342875.2342881},
 acmid = {2342881},
 publisher = {USENIX Association},
 address = {Berkeley, CA, USA}
} 


@misc {rapid7,
    author      = {Mark Stanislav},
    title       = {HACKING IoT: A Case Study on Baby Monitor Exposures and Vulnerabilities},
    institution = {Rapid7},
    year        = {2015},
    month       = {Sep}, 
   howpublished = {\url{https://www.rapid7.com/docs/Hacking-IoT-A-Case-Study-on-Baby-Monitor-Exposures-and-Vulnerabilities.pdf}},
   note = {Accessed: 2016-10-01}
    
    
}

@misc {dave,
    author      = "Dave Evans",
    title       = "The Internet of Things How the Next Evolution of the Internet Is Changing Everything",
    institution = "CISCO",
    year        = "2011",
    month       = "Apr",
    
    note = {Accessed: 2016-10-01},
    
     howpublished = {\url{https://www.cisco.com/c/dam/en_us/about/ac79/docs/innov/IoT_IBSG_0411FINAL.pdf}}
     
     
}


@book{Sayood:2000:IDC:336428,
 author = {Sayood, Khalid},
 title = {Introduction to Data Compression (2Nd Ed.)},
 year = {2000},
 isbn = {1-55860-558-4},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA}
} 

@article{Xie:2016:UID:2936026.2936232,
 author = {Xie, Yulai and Feng, Dan and Tan, Zhipeng and Zhou, Junzhe},
 title = {Unifying Intrusion Detection and Forensic Analysis via Provenance Awareness},
 journal = {Future Gener. Comput. Syst.},
 issue_date = {August 2016},
 volume = {61},
 number = {C},
 month = aug,
 year = {2016},
 issn = {0167-739X},
 pages = {26--36},
 numpages = {11},
 url = {http://dx.doi.org/10.1016/j.future.2016.02.005},
 doi = {10.1016/j.future.2016.02.005},
 acmid = {2936232},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 keywords = {False alarm, Forensic analysis, Intrusion detection, Provenance}
} 

@inproceedings{King:2003:BI:945445.945467,
 author = {King, Samuel T. and Chen, Peter M.},
 title = {Backtracking Intrusions},
 booktitle = {Proceedings of the Nineteenth ACM Symposium on Operating Systems Principles},
 series = {SOSP '03},
 year = {2003},
 isbn = {1-58113-757-5},
 location = {Bolton Landing, NY, USA},
 pages = {223--236},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/945445.945467},
 doi = {10.1145/945445.945467},
 acmid = {945467},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computer forensics, information flow, intrusion analysis}
} 


@inproceedings{Hasan:2009:CFP:1525908.1525909,
 author = {Hasan, Ragib and Sion, Radu and Winslett, Marianne},
 title = {The Case of the Fake Picasso: Preventing History Forgery with Secure Provenance},
 booktitle = {Proccedings of the 7th Conference on File and Storage Technologies},
 series = {FAST '09},
 year = {2009},
 location = {San Francisco, California},
 pages = {1--14},
 numpages = {14},
 url = {http://dl.acm.org/citation.cfm?id=1525908.1525909},
 acmid = {1525909},
 publisher = {USENIX Association},
 address = {Berkeley, CA, USA}
} 



@inproceedings{Ali:2013:PPL:2569433.2569893,
 author = {Ali, Mufajjul and Moreau, Luc},
 title = {A Provenance-Aware Policy Language (cProvl) and a Data Traceability Model (cProv) for the Cloud},
 booktitle = {Proceedings of the 2013 International Conference on Cloud and Green Computing},
 series = {CGC '13},
 year = {2013},
 isbn = {978-0-7695-5114-2},
 pages = {479--486},
 numpages = {8},
 url = {http://dx.doi.org/10.1109/CGC.2013.81},
 doi = {10.1109/CGC.2013.81},
 acmid = {2569893},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {policy language, provenance, cloud, cProvl, cProv, Prov, data traceability, XACML}
} 

@inproceedings{Ali:2014:PPC:2977935.2977949,
 author = {Ali, Mufajjul and Moreau, Luc},
 title = {A Provenance-Based Policy Control Framework for Cloud Services},
 booktitle = {Revised Selected Papers of the 5th International Provenance and Annotation Workshop on Provenance and Annotation of Data and Processes - Volume 8628},
 series = {IPAW 2014},
 year = {2015},
 isbn = {978-3-319-16461-8},
 location = {Cologne, Germany},
 pages = {127--138},
 numpages = {12},
 url = {http://dx.doi.org/10.1007/978-3-319-16462-5_10},
 doi = {10.1007/978-3-319-16462-5_10},
 acmid = {2977949},
 publisher = {Springer-Verlag New York, Inc.},
 address = {New York, NY, USA},
 keywords = {Cloud, Prov, Provenance, Share, XACML, cProv, cProvl}
} 

@Book{TCDP1999,
    publisher = {Cambridge University Press},
    author = {Rationality.},
    title = {{The Cambridge Dictionary of Philosophy}},
    year = {1999},
}

@misc {emc_bigdata,
    author      = "John Gantz, David Reinsel",
    title       = "THE DIGITAL UNIVERSE IN 2020: Big Data, Bigger Digital Shadows, and Biggest Growth in the Far East",
    institution = "EMC  Corporation",
    year        = "2012",
    month       = "apr",
    note = {Accessed: 2016-10-01},
    
    howpublished = "\url{https://www.emc.com/collateral/analyst-reports/idc-the-digital-universe-in-2020.pdf}"
}

@Inbook{Bertino2015,
author="Bertino, Elisa",
editor="Garcia-Alfaro, Joaquin
and Herrera-Joancomart{\'i}, Jordi
and Lupu, Emil
and Posegga, Joachim
and Aldini, Alessandro
and Martinelli, Fabio
and Suri, Neeraj",
title="Data Trustworthiness---Approaches and Research Challenges",
bookTitle="Data Privacy Management, Autonomous Spontaneous Security, and Security Assurance: 9th International Workshop, DPM 2014, 7th International Workshop, SETOP 2014,  and 3rd International Workshop, QASA 2014, Wroclaw, Poland, September 10-11, 2014. Revised Selected Papers",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="17--25",
isbn="978-3-319-17016-9",
doi="10.1007/978-3-319-17016-9_2",
url={"http://dx.doi.org/10.1007/978-3-319-17016-9_2"}
}

@inproceedings{zawoadfecloud,
  title={FECloud: A Trustworthy Forensics-Enabled Cloud Architecture},
  author={Zawoad, Shams and Hasan, Ragib},
  bookTitle= {11th Annual IFIP WG 11 International Conference on Digital Forensics}, 
  year = {2015}
}

@inproceedings{braun2006issues,
  title={Issues in automatic provenance collection},
  author={Braun, Uri and Garfinkel, Simson and Holland, David A and Muniswamy-Reddy, Kiran-Kumar and Seltzer, Margo I},
  bookTitle={International Provenance and Annotation Workshop},
  pages={171--183},
  year={2006},
  organization={Springer}
}

@inproceedings{Smets2011TheOO,
  title={The Odd One Out: Identifying and Characterising Anomalies},
  author={Koen Smets and Jilles Vreeken},
  booktitle={SDM},
  year={2011}
}


@inproceedings{Bates2014LinuxPM,
  title={Linux Provenance Modules: Secure Provenance Collection for the Linux Kernel},
  author={Adam Bates and Kevin R B Butler and Thomas Moyer},
  year={2014}
}

@inproceedings{Bates:2015:TOY:2814579.2814586,
 author = {Bates, Adam and Butler, Kevin R. B. and Moyer, Thomas},
 title = {Take Only What You Need: Leveraging Mandatory Access Control Policy to Reduce Provenance Storage Costs},
 booktitle = {Proceedings of the 7th USENIX Conference on Theory and Practice of Provenance},
 series = {TaPP'15},
 year = {2015},
 location = {Edinburgh, Scotland},
 pages = {7--7},
 numpages = {1},
 url = {http://dl.acm.org/citation.cfm?id=2814579.2814586},
 acmid = {2814586},
 publisher = {USENIX Association},
 address = {Berkeley, CA, USA}
} 

@inproceedings{asiaccs12-vijayakumar,
   author = {Hayawardh Vijayakumar and Joshua Schiffman and Trent Jaeger},
   title = {Integrity Walls: Finding attack surfaces from mandatory access
	control policies},
   booktitle = {7th ACM Symposium on Information, Computer, and
	Communications Security (ASIACCS)},
   month = may,
   year = {2012}
}

@misc{rfc2748,
	series =	{Request for Comments},
	number=		2748,
	publisher =	{RFC Editor},
	doi =		{10.17487/rfc2748},
	url =		{https://rfc-editor.org/rfc/rfc2748.txt},
	author=		{Shai Herzog},
	title=		{{The COPS (Common Open Policy Service) Protocol}},
	pagetotal =	38,
	year =		2013,
	month =		mar,
	day =		2,
	abstract =	{This document describes a simple client/server model for supporting policy control over QoS signaling protocols. [STANDARDS-TRACK]},
	note = {Accessed: 2016-10-01},
	howpublished = {\url{https://tools.ietf.org/html/rfc2748}}	
}



%IDS Paper


@inproceedings{liao_using_2002,
	address = {Berkeley, CA, USA},
	title = {Using {Text} {Categorization} {Techniques} for {Intrusion} {Detection}},
	isbn = {978-1-931971-00-3},
	url = {http://dl.acm.org/citation.cfm?id=647253.720290},
	booktitle = {Proceedings of the 11th {USENIX} {Security} {Symposium}},
	publisher = {USENIX Association},
	author = {Liao, Yihua and Vemuri, V. Rao},
	year = {2002},
	pages = {51--59}
}

@article{barcena2015insecurity,
  title={Insecurity in the Internet of Things},
  author={Barcena, Mario Ballano and Wueest, Candid},
  url="https://www.symantec.com/content/dam/symantec/docs/white-papers/insecurity-in-the-internet-of-things-en.pdf"
}

@article{smart_thermostat,
  title={DefCon: Thermostat Control Hacked to Host Ransomware},
  author={Raywood, Dan},
  year={2016},
  url="https://www.infosecurity-magazine.com/news/defcon-thermostat-control-hacked/"
}

@Inbook{Lazarevic2005,
author="Lazarevic, Aleksandar
and Kumar, Vipin
and Srivastava, Jaideep",
editor="Kumar, Vipin
and Srivastava, Jaideep
and Lazarevic, Aleksandar",
title="Intrusion Detection: A Survey",
bookTitle="Managing Cyber Threats: Issues, Approaches, and Challenges",
year="2005",
publisher="Springer US",
address="Boston, MA",
pages="19--78",
abstract="This chapter provides the overview of the state of the art in intrusion detection research. Intrusion detection systems are software and/or hardware components that monitor computer systems and analyze events occurring in them for signs of intrusions. Due to widespread diversity and complexity of computer infrastructures, it is difficult to provide a completely secure computer system. Therefore, there are numerous security systems and intrusion detection systems that address different aspects of computer security. This chapter first provides taxonomy of computer intrusions, along with brief descriptions of major computer attack categories. Second, a common architecture of intrusion detection systems and their basic characteristics are presented. Third, taxonomy of intrusion detection systems based on five criteria (information source, analysis strategy, time aspects, architecture, response) is given. Finally, intrusion detection systems are classified according to each of these categories and the most representative research prototypes are briefly described.",
isbn="978-0-387-24230-9",
doi="10.1007/0-387-24230-9_2",
url="https://doi.org/10.1007/0-387-24230-9_2"
}



@article{LANGEVIN201594,
title = "Tracking the human-building interaction: A longitudinal field study of occupant behavior in air-conditioned offices",
journal = "Journal of Environmental Psychology",
volume = "42",
number = "Supplement C",
pages = "94 - 115",
year = "2015",
issn = "0272-4944",
doi = "https://doi.org/10.1016/j.jenvp.2015.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S0272494415000225",
author = "Jared Langevin and Patrick L. Gurian and Jin Wen",
keywords = "Occupant behavior, Thermal comfort, Thermal acceptability, Longitudinal field studies, Office buildings"
}

@article{jeep_vulnerabilty,
  title={THE JEEP HACKERS ARE BACK TO PROVE CAR HACKING CAN GET MUCH WORSE},
  author={Greenberg, Andy},
  year={2015},
  url="https://www.wired.com/2016/08/jeep-hackers-return-high-speed-steering-acceleration-hacks/"
}

@article {dave,
    author      = "Dave Evans",
    title       = "The Internet of Things How the Next Evolution of the Internet Is Changing Everything",
    institution = "CISCO",
    year        = "2011",
    month       = "Apr",
    
    note = {Accessed: 2016-10-01},
    
     howpublished = {\url{https://www.cisco.com/c/dam/en_us/about/ac79/docs/innov/IoT_IBSG_0411FINAL.pdf}}
     
     
}

@ARTICLE{5968088, 
author={D. P. Fidler}, 
journal={IEEE Security Privacy}, 
title={Was Stuxnet an Act of War? Decoding a Cyberattack}, 
year={2011}, 
volume={9}, 
number={4}, 
pages={56-59}, 
keywords={computer network security;data privacy;decoding;national security;Stuxnet;cyberattack decoding;cyberspace;human security;online privacy;Computer security;Information security;Legal factors;Privacy;Aggression;Stuxnet;armed attack;cybersecurity;cyberweapons;international law;intervention;use of force;war}, 
doi={10.1109/MSP.2011.96}, 
ISSN={1540-7993}, 
month={July},}

@article{gartner,
  title={Insecurity in the Internet of Things},
  author={Gartner},
  url="http://www.gartner.com/newsroom/id/2905717"
 
}

@article{hp,
  title={Internet of things research study},
  author={HP},
  url="http://h20195.www2.hpe.com/V4/getpdf.aspx/4aa5-4759enn"
}

@Article{Akoglu2015,
author="Akoglu, Leman
and Tong, Hanghang
and Koutra, Danai",
title="Graph based anomaly detection and description: a survey",
journal="Data Mining and Knowledge Discovery",
year="2015",
month="May",
day="01",
volume="29",
number="3",
pages="626--688",
abstract="Detecting anomalies in data is a vital task, with numerous high-impact applications in areas such as security, finance, health care, and law enforcement. While numerous techniques have been developed in past years for spotting outliers and anomalies in unstructured collections of multi-dimensional points, with graph data becoming ubiquitous, techniques for structured graph data have been of focus recently. As objects in graphs have long-range correlations, a suite of novel technology has been developed for anomaly detection in graph data. This survey aims to provide a general, comprehensive, and structured overview of the state-of-the-art methods for anomaly detection in data represented as graphs. As a key contribution, we give a general framework for the algorithms categorized under various settings: unsupervised versus (semi-)supervised approaches, for static versus dynamic graphs, for attributed versus plain graphs. We highlight the effectiveness, scalability, generality, and robustness aspects of the methods. What is more, we stress the importance of anomaly attribution and highlight the major techniques that facilitate digging out the root cause, or the `why', of the detected anomalies for further analysis and sense-making. Finally, we present several real-world applications of graph-based anomaly detection in diverse domains, including financial, auction, computer traffic, and social networks. We conclude our survey with a discussion on open theoretical and practical challenges in the field.",
issn="1573-756X",
doi="10.1007/s10618-014-0365-y",
url="https://doi.org/10.1007/s10618-014-0365-y"
}





@inproceedings{manzoor_fast_2016,
	address = {New York, NY, USA},
	series = {{KDD} '16},
	title = {Fast {Memory}-efficient {Anomaly} {Detection} in {Streaming} {Heterogeneous} {Graphs}},
	isbn = {978-1-4503-4232-2},
	url = {http://doi.acm.org/10.1145/2939672.2939783},
	doi = {10.1145/2939672.2939783},
	abstract = {Given a stream of heterogeneous graphs containing different types of nodes and edges, how can we spot anomalous ones in real-time while consuming bounded memory? This problem is motivated by and generalizes from its application in security to host-level advanced persistent threat (APT) detection. We propose StreamSpot, a clustering based anomaly detection approach that addresses challenges in two key fronts: (1) heterogeneity, and (2) streaming nature. We introduce a new similarity function for heterogeneous graphs that compares two graphs based on their relative frequency of local substructures, represented as short strings. This function lends itself to a vector representation of a graph, which is (a) fast to compute, and (b) amenable to a sketched version with bounded size that preserves similarity. StreamSpot exhibits desirable properties that a streaming application requires: it is (i) fully-streaming; processing the stream one edge at a time as it arrives, (ii) memory-efficient; requiring constant space for the sketches and the clustering, (iii) fast; taking constant time to update the graph sketches and the cluster summaries that can process over 100,000 edges per second, and (iv) online; scoring and flagging anomalies in real time. Experiments on datasets containing simulated system-call flow graphs from normal browser activity and various attack scenarios (ground truth) show that StreamSpot is high-performance; achieving above 95\% detection accuracy with small delay, as well as competitive time and memory usage.},
	booktitle = {Proceedings of the 22Nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Manzoor, Emaad and Milajerdi, Sadegh M. and Akoglu, Leman},
	year = {2016},
	keywords = {anomaly detection, dynamic networks, evolving graphs, graph sketches, heterogenous graphs, streamspot, temporal networks, typed graphs},
	pages = {1035--1044},
	file = {ACM Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/HW2X343J/Manzoor et al. - 2016 - Fast Memory-efficient Anomaly Detection in Streami.pdf:application/pdf}
}

@article{chandola_anomaly_2009,
	title = {Anomaly {Detection}: {A} {Survey}},
	volume = {41},
	issn = {0360-0300},
	shorttitle = {Anomaly {Detection}},
	url = {http://doi.acm.org/10.1145/1541880.1541882},
	doi = {10.1145/1541880.1541882},
	abstract = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
	number = {3},
	journal = {ACM Comput. Surv.},
	author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
	month = jul,
	year = {2009},
	keywords = {anomaly detection, outlier detection},
	pages = {15:1--15:58},
	file = {ACM Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/7DJ89GGW/Chandola et al. - 2009 - Anomaly Detection A Survey.pdf:application/pdf}
}

@inproceedings{hautamaki_outlier_2004,
	address = {Washington, DC, USA},
	series = {{ICPR} '04},
	title = {Outlier {Detection} {Using} k-{Nearest} {Neighbour} {Graph}},
	isbn = {978-0-7695-2128-2},
	url = {http://dx.doi.org/10.1109/ICPR.2004.671},
	doi = {10.1109/ICPR.2004.671},
	abstract = {We present an Outlier Detection using Indegree Number (ODIN) algorithm that utilizes k-nearest neighbour graph. Improvements to existing kNN distance-based method are also proposed. We compare the methods with real and synthetic datasets. The results show that the proposed method achieves resonable results with synthetic data and outperforms compared methods with real data sets with small number of observations.},
	booktitle = {Proceedings of the {Pattern} {Recognition}, 17th {International} {Conference} on ({ICPR}'04) {Volume} 3 - {Volume} 03},
	publisher = {IEEE Computer Society},
	author = {Hautamaki, Ville and Karkkainen, Ismo and Franti, Pasi},
	year = {2004},
	pages = {430--433}
}

@inproceedings{paiot,
	address = {San Fransisco, CA, USA},
	series = {UIC '17},
	title = {Towards a Provenance Aware Framework for Internet of Things Devices},
	booktitle = {Proceedings of the 14th International Conference on Ubiquitous Intelligence and Computing},
	publisher = {IEEE Computer Society},
	author = {Nwafor, Ebelechukwu and Hill, David and Campbell, Andre and Bloom, Gedare},
	year = {2017}
	
}

@inproceedings{Ramaswamy,
 author = {Ramaswamy, Sridhar and Rastogi, Rajeev and Shim, Kyuseok},
 title = {Efficient Algorithms for Mining Outliers from Large Data Sets},
 booktitle = {Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '00},
 year = {2000},
 isbn = {1-58113-217-4},
 location = {Dallas, Texas, USA},
 pages = {427--438},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/342009.335437},
 doi = {10.1145/342009.335437},
 acmid = {335437},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@article{akoglu_graph_2015,
	title = {Graph {Based} {Anomaly} {Detection} and {Description}: {A} {Survey}},
	volume = {29},
	issn = {1384-5810},
	shorttitle = {Graph {Based} {Anomaly} {Detection} and {Description}},
	url = {http://dx.doi.org/10.1007/s10618-014-0365-y},
	doi = {10.1007/s10618-014-0365-y},
	abstract = {Detecting anomalies in data is a vital task, with numerous high-impact applications in areas such as security, finance, health care, and law enforcement. While numerous techniques have been developed in past years for spotting outliers and anomalies in unstructured collections of multi-dimensional points, with graph data becoming ubiquitous, techniques for structured graph data have been of focus recently. As objects in graphs have long-range correlations, a suite of novel technology has been developed for anomaly detection in graph data. This survey aims to provide a general, comprehensive, and structured overview of the state-of-the-art methods for anomaly detection in data represented as graphs. As a key contribution, we give a general framework for the algorithms categorized under various settings: unsupervised versus (semi-)supervised approaches, for static versus dynamic graphs, for attributed versus plain graphs. We highlight the effectiveness, scalability, generality, and robustness aspects of the methods. What is more, we stress the importance of anomaly attribution and highlight the major techniques that facilitate digging out the root cause, or the `why', of the detected anomalies for further analysis and sense-making. Finally, we present several real-world applications of graph-based anomaly detection in diverse domains, including financial, auction, computer traffic, and social networks. We conclude our survey with a discussion on open theoretical and practical challenges in the field.},
	number = {3},
	journal = {Data Min. Knowl. Discov.},
	author = {Akoglu, Leman and Tong, Hanghang and Koutra, Danai},
	month = may,
	year = {2015},
	keywords = {Anomaly description, anomaly detection, Change point detection, Event detection, Fraud detection, Graph mining, Network anomaly detection, Visual analytics},
	pages = {626--688}
}

@article{Hofmeyr,
 author = {Hofmeyr, Steven A. and Forrest, Stephanie and Somayaji, Anil},
 title = {Intrusion Detection Using Sequences of System Calls},
 journal = {J. Comput. Secur.},
 issue_date = {August 1998},
 volume = {6},
 number = {3},
 month = aug,
 year = {1998},
 issn = {0926-227X},
 pages = {151--180},
 numpages = {30},
 url = {http://dl.acm.org/citation.cfm?id=1298081.1298084},
 acmid = {1298084},
 publisher = {IOS Press},
 address = {Amsterdam, The Netherlands, The Netherlands},
}

@inproceedings{kumar_approach_2015,
	address = {New York, NY, USA},
	series = {{ICEMIS} '15},
	title = {An {Approach} for {Intrusion} {Detection} {Using} {Text} {Mining} {Techniques}},
	isbn = {978-1-4503-3418-1},
	url = {http://doi.acm.org/10.1145/2832987.2833076},
	doi = {10.1145/2832987.2833076},
	abstract = {The problem of clustering is NP-Complete. The existing clustering algorithm in literature is the approximate algorithms, which cluster the underlying data differently for different datasets. The K-Means Clustering algorithm is suitable for frequency but not for binary form. When an application runs several system calls are implicitly invoked in the background. Based on these system calls we can predict the normal or abnormal behavior of applications. This can be done by classification. In this paper we tried to perform classification of processes running into normal and abnormal states by using system call behavior. We reduce the system call feature vector by choosing k-means algorithm which uses the proposed measure for dimensionality reduction. We give the design of the proposed measure. The proposed measure has upper and lower bounds which are finite.},
	booktitle = {Proceedings of the {The} {International} {Conference} on {Engineering} \& {MIS} 2015},
	publisher = {ACM},
	author = {Kumar, Gunupudi Rajesh and Mangathayaru, N. and Narasimha, G.},
	year = {2015},
	keywords = {Classifier, Intrusion, Malicious, Nearest Neighbor, System Call},
	pages = {63:1--63:6},
	file = {ACM Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/CHCBZKQF/Kumar et al. - 2015 - An Approach for Intrusion Detection Using Text Min.pdf:application/pdf}
}

@article{lundin_anomaly-based_2000,
	title = {Anomaly-based {Intrusion} {Detection}: {Privacy} {Concerns} and {Other} {Problems}},
	volume = {34},
	issn = {1389-1286},
	shorttitle = {Anomaly-based {Intrusion} {Detection}},
	url = {http://dx.doi.org/10.1016/S1389-1286(00)00134-1},
	doi = {10.1016/S1389-1286(00)00134-1},
	number = {4},
	journal = {Comput. Netw.},
	author = {Lundin, Emilie and Jonsson, Erland},
	month = oct,
	year = {2000},
	keywords = {anomaly detection, Intrusion detection, Privacy, pseudonymization},
	pages = {623--640}
}

@misc{noauthor_survey_nodate,
	title = {Survey of {Nearest} {Neighbor} {Techniques} - {Semantic} {Scholar}},
	url = {/paper/Survey-of-Nearest-Neighbor-Techniques-Bhatia-Vandana/ca2bfcf88873cce70e92b160bf0b6a2472c2fee7},
	abstract = {— The nearest neighbor (NN) technique is very simple, highly efficient and effective in the field of pattern recognition, text categorization, object recognition etc. Its simplicity is its main advantage, but the disadvantages can\&\#39;t be ignored even. The memory requirement and computation complexity also matter. Many techniques are developed to overcome these limitations. NN techniques are broadly classified into structure less and structure based techniques. In this paper, we present the survey of such techniques. structure based algorithms developed on the basis of kNN. The structure less method overcome memory limitation and structure based techniques reduce the computational complexity.},
	urldate = {2017-07-05},
	file = {Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/B7K74JWE/ca2bfcf88873cce70e92b160bf0b6a2472c2fee7.html:text/html}
}

@misc{noauthor_revisiting_nodate,
	title = {Revisiting {End}-to-{End} {Trace} {Comparison} with {Graph} {Kernels} - {Semantic} {Scholar}},
	url = {/paper/Revisiting-End-to-End-Trace-Comparison-with-Graph-Mace-Fonseca/26816c083e05ba5ec2542d0ee064d442fe43b3d6},
	abstract = {End-to-end tracing has emerged recently as a valuable tool to improve the dependability of distributed systems by performing dynamic verification and diagnosing cor-rectness and performance problems. End-to-end traces are commonly represented as richly annotated directed acyclic graphs, with events as nodes and their causal dependencies as edges. Being able to automatically compare these graphs at scale is a key primitive for tasks such as clustering, classification, and anomaly detection. In this paper we explore recent developments in the theory of graph kernels, and investigate the feasibility of using a family of kernels based on the Weisfeiler-Lehman graph isomorphism test [35] as an efficient and robust graph comparison primitive. We find that graph kernels provide a good formulation of the execution graph comparison problem, and present preliminary but encouraging results on their ability to distinguish high-level differences between execution graphs.},
	urldate = {2017-07-08},
	file = {Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/FJ8MQD95/26816c083e05ba5ec2542d0ee064d442fe43b3d6.html:text/html}
}

@inproceedings{denning_intrusion-detection_1986,
	title = {An {Intrusion}-{Detection} {Model}},
	doi = {10.1109/SP.1986.10010},
	abstract = {A model of a real-time intrusion-detection expert system capable of detecting break-ins, penetrations, and other forms of computer abuse is described. The model is based on the hypothesis that security violations can be detected by monitoring a system's audit records for abnormal patterns of system usage. The model includes profiles for representing the behavior of subjects with respect to objects in terms of metrics and statistical models, and rules for acquiring knowledge about this behavior from audit records and for detecting anomalous behavior. The model is independent of any particular system, application environment, system vulnerability, or type of intrusion, thereby providing a framework for a general-purpose intrusion-detection expert system.},
	booktitle = {1986 {IEEE} {Symposium} on {Security} and {Privacy}},
	author = {Denning, D. E.},
	month = apr,
	year = {1986},
	keywords = {Computational modeling, Expert systems, Measurement, Monitoring, Radiation detectors, Security, Standards},
	pages = {118--118},
	file = {IEEE Xplore Abstract Record:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/43KEWIGT/6234848.html:text/html}
}

@inproceedings{ghosh_learning_1999,
	address = {Berkeley, CA, USA},
	series = {{ID}'99},
	title = {Learning {Program} {Behavior} {Profiles} for {Intrusion} {Detection}},
	url = {http://dl.acm.org/citation.cfm?id=1267880.1267886},
	abstract = {Profiling the behavior of programs can be a useful reference for detecting potential intrusions against systems. This paper presents three anomaly detection techniques for profiling program behavior that evolve from memorization to generalization. The goal of monitoring program behavior is to be able to detect potential intrusions by noting irregularities in program behavior. The techniques start from a simple equality matching algorithm for determining anomalous behavior, and evolve to a feed-forward backpropagation neural network for learning program behavior, and finally to an Elman network for recognizing recurrent features in program execution traces. In order to detect future attacks against systems, intrusion detection systems must be able to generalize from past observed behavior. The goal of this research is to employ machine learning techniques that can generalize from past observed behavior to the problem of intrusion detection. The performance of these systems is compared by testing them with data provided by the DARPA Intrusion Detection Evaluation program.},
	booktitle = {Proceedings of the 1st {Conference} on {Workshop} on {Intrusion} {Detection} and {Network} {Monitoring} - {Volume} 1},
	publisher = {USENIX Association},
	author = {Ghosh, Anup K. and Schwartzbard, Aaron and Schatz, Michael},
	year = {1999},
	pages = {6--6}
}

@article{hodge_survey_2004,
	title = {A {Survey} of {Outlier} {Detection} {Methodologies}},
	volume = {22},
	issn = {0269-2821, 1573-7462},
	url = {https://link.springer.com/article/10.1023/B:AIRE.0000045502.10941.a9},
	doi = {10.1023/B:AIRE.0000045502.10941.a9},
	abstract = {Outlier detection has been used for centuries to detect and, where appropriate, remove anomalous observations from data. Outliers arise due to mechanical faults, changes in system behaviour, fraudulent behaviour, human error, instrument error or simply through natural deviations in populations. Their detection can identify system faults and fraud before they escalate with potentially catastrophic consequences. It can identify errors and remove their contaminating effect on the data set and as such to purify the data for processing. The original outlier detection methods were arbitrary but now, principled and systematic techniques are used, drawn from the full gamut of Computer Science and Statistics. In this paper, we introduce a survey of contemporary techniques for outlier detection. We identify their respective motivations and distinguish their advantages and disadvantages in a comparative review.},
	language = {en},
	number = {2},
	urldate = {2017-07-28},
	journal = {Artificial Intelligence Review},
	author = {Hodge, Victoria and Austin, Jim},
	month = oct,
	year = {2004},
	pages = {85--126},
	file = {Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/MVK6923V/10.1023BAIRE.0000045502.10941.html:text/html}
}

@article{hodge_survey_2004-1,
	title = {A {Survey} of {Outlier} {Detection} {Methodologies}},
	volume = {22},
	issn = {0269-2821, 1573-7462},
	url = {https://link.springer.com/article/10.1007/s10462-004-4304-y},
	doi = {10.1007/s10462-004-4304-y},
	abstract = {Outlier detection has been used for centuries to detect and, where appropriate, remove anomalous observations from data. Outliers arise due to mechanical faults, changes in system behaviour, fraudulent behaviour, human error, instrument error or simply through natural deviations in populations. Their detection can identify system faults and fraud before they escalate with potentially catastrophic consequences. It can identify errors and remove their contaminating effect on the data set and as such to purify the data for processing. The original outlier detection methods were arbitrary but now, principled and systematic techniques are used, drawn from the full gamut of Computer Science and Statistics. In this paper, we introduce a survey of contemporary techniques for outlier detection. We identify their respective motivations and distinguish their advantages and disadvantages in a comparative review.},
	language = {en},
	number = {2},
	urldate = {2017-07-28},
	journal = {Artificial Intelligence Review},
	author = {Hodge, Victoria J. and Austin, Jim},
	month = oct,
	year = {2004},
	pages = {85--126},
	file = {Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/P2J43SRT/10.html:text/html}
}

@inproceedings{ghosh1994credit,
  title={Credit card fraud detection with a neural-network},
  author={Ghosh, Sushmito and Reilly, Douglas L},
  booktitle={System Sciences, 1994. Proceedings of the Twenty-Seventh Hawaii International Conference on},
  volume={3},
  pages={621--630},
  year={1994},
  organization={IEEE}
}

@inproceedings{chakrabarti2004autopart,
  title={Autopart: Parameter-free graph partitioning and outlier detection},
  author={Chakrabarti, Deepayan},
  booktitle={European Conference on Principles of Data Mining and Knowledge Discovery},
  pages={112--124},
  year={2004},
  organization={Springer}
}

@inproceedings{valko2008conditional,
  title={Conditional anomaly detection methods for patient--management alert systems},
  author={Valko, Michal and Cooper, Gregory and Seybert, Amy and Visweswaran, Shyam and Saul, Melissa and Hauskrecht, Milos},
  booktitle={Proceedings of the... International Conference on Machine Learning. International Conference on Machine Learning},
  volume={2008},
  year={2008},
  organization={NIH Public Access}
}

@inproceedings{warrender1999detecting,
  title={Detecting intrusions using system calls: Alternative data models},
  author={Warrender, Christina and Forrest, Stephanie and Pearlmutter, Barak},
  booktitle={Security and Privacy, 1999. Proceedings of the 1999 IEEE Symposium on},
  pages={133--145},
  year={1999},
  organization={IEEE}
}

@inproceedings{lane1997sequence,
  title={Sequence matching and learning in anomaly detection for computer security},
  author={Lane, Terran and Brodley, Carla E and others},
  booktitle={AAAI Workshop: AI Approaches to Fraud Detection and Risk Management},
  pages={43--49},
  year={1997}
}

@inproceedings{Yoon,
 author = {Yoon, Man-Ki and Mohan, Sibin and Choi, Jaesik and Christodorescu, Mihai and Sha, Lui},
 title = {Learning Execution Contexts from System Call Distribution for Anomaly Detection in Smart Embedded System},
 booktitle = {Proceedings of the Second International Conference on Internet-of-Things Design and Implementation},
 series = {IoTDI '17},
 year = {2017},
 isbn = {978-1-4503-4966-6},
 location = {Pittsburgh, PA, USA},
 pages = {191--196},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/3054977.3054999},
 doi = {10.1145/3054977.3054999},
 acmid = {3054999},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Anomaly Detection, Embedded Systems, Security},
} 

@article{zhang_outlier_2010,
	title = {Outlier {Detection} {Techniques} for {Wireless} {Sensor} {Networks}: {A} {Survey}},
	volume = {12},
	issn = {1553-877X},
	shorttitle = {Outlier {Detection} {Techniques} for {Wireless} {Sensor} {Networks}},
	doi = {10.1109/SURV.2010.021510.00088},
	abstract = {In the field of wireless sensor networks, those measurements that significantly deviate from the normal pattern of sensed data are considered as outliers. The potential sources of outliers include noise and errors, events, and malicious attacks on the network. Traditional outlier detection techniques are not directly applicable to wireless sensor networks due to the nature of sensor data and specific requirements and limitations of the wireless sensor networks. This survey provides a comprehensive overview of existing outlier detection techniques specifically developed for the wireless sensor networks. Additionally, it presents a technique-based taxonomy and a comparative table to be used as a guideline to select a technique suitable for the application at hand based on characteristics such as data type, outlier type, outlier identity, and outlier degree.},
	number = {2},
	journal = {IEEE Communications Surveys Tutorials},
	author = {Zhang, Y. and Meratnia, N. and Havinga, P.},
	year = {2010},
	keywords = {data type, Outlier, outlier degree, outlier detection, outlier detection techniques, outlier identity, outlier type, sensor data, taxonomy, technique-based taxonomy, Wireless sensor networks},
	pages = {159--170},
	file = {IEEE Xplore Abstract Record:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/AQU5EDUB/5451757.html:text/html}
}

@techreport{marghny_outlier_2011,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Outlier {Detection} {Using} {Improved} {Genetic} {K}-{Means}},
	url = {https://papers.ssrn.com/abstract=2545143},
	abstract = {The outlier detection problem in some cases is similar to the classification problem. For example, the main concern of clustering-based outlier detection algorithms is to find clusters and outliers, which are often regarded as noise that should be removed in order to make more reliable clustering. In this article, we present an algorithm that provides outlier detection and data clustering simultaneously. The algorithm improves the estimation of centroids of the generative distribution during the process of clustering and outlier discovery. The proposed algorithm consists of two stages. The first stage consists of improved genetic k-means algorithm (IGK) process, while the second stage iteratively removes the vectors which are far from their cluster centroids.},
	number = {ID 2545143},
	urldate = {2017-07-30},
	institution = {Social Science Research Network},
	author = {Marghny, M. H. and Taloba, Ahmed I.},
	month = aug,
	year = {2011},
	keywords = {Clustering, Genetic algorithms, Improved Genetic K-means (IGK), K-means algorithm, outlier detection},
	file = {Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/THMGXVZI/papers.html:text/html}
}

@inproceedings{lamba_model-based_2016,
	address = {New York, NY, USA},
	series = {{HotSos} '16},
	title = {A {Model}-based {Approach} to {Anomaly} {Detection} in {Software} {Architectures}},
	isbn = {978-1-4503-4277-3},
	url = {http://doi.acm.org/10.1145/2898375.2898401},
	doi = {10.1145/2898375.2898401},
	abstract = {In an organization, the interactions users have with software leave patterns or traces of the parts of the systems accessed. These interactions can be associated with the underlying software architecture. The first step in detecting problems like insider threat is to detect those traces that are anomalous. Here, we propose a method to find anomalous users leveraging these interaction traces, categorized by user roles. We propose a model based approach to cluster user sequences and find outliers. We show that the approach works on a simulation of a large scale system based on and Amazon Web application style.},
	booktitle = {Proceedings of the {Symposium} and {Bootcamp} on the {Science} of {Security}},
	publisher = {ACM},
	author = {Lamba, Hemank and Glazier, Thomas J. and Schmerl, Bradley and Cámara, Javier and Garlan, David and Pfeffer, Jürgen},
	year = {2016},
	keywords = {anomaly detection, model-based graph clustering},
	pages = {69--71}
}

@article{ulvila_evaluation_2003,
	title = {Evaluation of {Intrusion} {Detection} {Systems}},
	volume = {108},
	issn = {1044-677X},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4844520/},
	doi = {10.6028/jres.108.040},
	abstract = {This paper presents a comprehensive method for evaluating intrusion detection systems (IDSs). It integrates and extends ROC (receiver operating characteristic) and cost analysis methods to provide an expected cost metric. Results are given for determining the optimal operation of an IDS based on this expected cost metric. Results are given for the operation of a single IDS and for a combination of two IDSs. The method is illustrated for: 1) determining the best operating point for a single and double IDS based on the costs of mistakes and the hostility of the operating environment as represented in the prior probability of intrusion and 2) evaluating single and double IDSs on the basis of expected cost. A method is also described for representing a compound IDS as an equivalent single IDS. Results are presented from the point of view of a system administrator, but they apply equally to designers of IDSs.},
	number = {6},
	journal = {Journal of Research of the National Institute of Standards and Technology},
	author = {Ulvila, Jacob W. and Gaffney, John E.},
	year = {2003},
	pmid = {27413623},
	pmcid = {PMC4844520},
	pages = {453--473},
	file = {PubMed Central Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/KP6DSX44/Ulvila and Gaffney - 2003 - Evaluation of Intrusion Detection Systems.pdf:application/pdf}
}

@inproceedings{aggarwal_outlier_2011,
	title = {Outlier detection in graph streams},
	doi = {10.1109/ICDE.2011.5767885},
	abstract = {A number of applications in social networks, telecommunications, and mobile computing create massive streams of graphs. In many such applications, it is useful to detect structural abnormalities which are different from the “typical” behavior of the underlying network. In this paper, we will provide first results on the problem of structural outlier detection in massive network streams. Such problems are inherently challenging, because the problem of outlier detection is specially challenging because of the high volume of the underlying network stream. The stream scenario also increases the computational challenges for the approach. We use a structural connectivity model in order to define outliers in graph streams. In order to handle the sparsity problem of massive networks, we dynamically partition the network in order to construct statistically robust models of the connectivity behavior. We design a reservoir sampling method in order to maintain structural summaries of the underlying network. These structural summaries are designed in order to create robust, dynamic and efficient models for outlier detection in graph streams. We present experimental results illustrating the effectiveness and efficiency of our approach.},
	booktitle = {2011 {IEEE} 27th {International} {Conference} on {Data} {Engineering}},
	author = {Aggarwal, C. C. and Zhao, Y. and Yu, P. S.},
	month = apr,
	year = {2011},
	keywords = {Estimation, graph streams, Image edge detection, massive network streams, media streaming, mobile computing, network theory (graphs), Probability, Reservoirs, reservoir sampling method, Robustness, sampling methods, social networking (online), social networks, Social network services, sparsity problem, structural connectivity model, structural outlier detection, telecommunications},
	pages = {399--409},
	file = {IEEE Xplore Abstract Record:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/WDCQGQGB/5767885.html:text/html}
}

@misc{noauthor_outlier_nodate,
	title = {Outlier detection for high dimensional data},
	url = {http://dl.acm.org/citation.cfm?id=375668},
	urldate = {2017-08-17}
}

@misc{noauthor_online_nodate,
	title = {Online outlier detection in sensor data using non-parametric models},
	url = {http://dl.acm.org/citation.cfm?id=1164145},
	urldate = {2017-08-17}
}

@misc{noauthor_web_nodate,
	title = {Web graph similarity for anomaly detection {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/s13174-010-0003-x},
	urldate = {2017-08-17}
}

@inproceedings{liao_using_2002-1,
	address = {Berkeley, CA, USA},
	title = {Using {Text} {Categorization} {Techniques} for {Intrusion} {Detection}},
	isbn = {978-1-931971-00-3},
	url = {http://dl.acm.org/citation.cfm?id=647253.720290},
	booktitle = {Proceedings of the 11th {USENIX} {Security} {Symposium}},
	publisher = {USENIX Association},
	author = {Liao, Yihua and Vemuri, V. Rao},
	year = {2002},
	pages = {51--59}
}

@book{hawkins,
  added-at = {2009-08-21T09:49:34.000+0200},
  address = {London [u.a.]},
  author = {Hawkins, {D. M.}},
  biburl = {https://www.bibsonomy.org/bibtex/2a18a993511eae14be1e4afcb6781ea58/fbw_hannover},
  interhash = {354e966642b8cb841f0b279a019a5aa9},
  intrahash = {a18a993511eae14be1e4afcb6781ea58},
  isbn = {041221900X},
  keywords = {imported},
  pagetotal = {X, 188},
  ppn_gvk = {02435757X},
  publisher = {Chapman and Hall},
  series = {Monographs on applied probability and statistics},
  timestamp = {2009-08-21T09:50:25.000+0200},
  title = {Identification of outliers},
  url = {http://gso.gbv.de/DB=2.1/CMD?ACT=SRCHA&SRT=YOP&IKT=1016&TRM=ppn+02435757X\&sourceid=fbw_bibsonomy},
  year = 1980
}

@Inbook{Bertino2015,
author="Bertino, Elisa",
editor="Garcia-Alfaro, Joaquin
and Herrera-Joancomart{\'i}, Jordi
and Lupu, Emil
and Posegga, Joachim
and Aldini, Alessandro
and Martinelli, Fabio
and Suri, Neeraj",
title="Data Trustworthiness---Approaches and Research Challenges",
bookTitle="Data Privacy Management, Autonomous Spontaneous Security, and Security Assurance: 9th International Workshop, DPM 2014, 7th International Workshop, SETOP 2014,  and 3rd International Workshop, QASA 2014, Wroclaw, Poland, September 10-11, 2014. Revised Selected Papers",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="17--25",
abstract="With the increased need of data sharing among multiple organizations, such as government organizations, financial corporations, medical hospitals and academic institutions, it is critical to assess and assure data trustworthiness so that effective decisions can be made based on data. In this paper, we first discuss motivations and relevant techniques for data trustworthiness. We then present an architectural framework for a comprehensive system for trustworthiness assurance and discuss relevant recent work. We highlight open research issues and research directions throughout the paper.",
isbn="978-3-319-17016-9",
doi="10.1007/978-3-319-17016-9_2",
url="https://doi.org/10.1007/978-3-319-17016-9_2"
}

@conference {pasquier-socc2017,
	title = {Practical Whole-System Provenance Capture},
	booktitle = {Symposium on Cloud Computing (SoCC{\textquoteright}17)},
	year = {2017},
	publisher = {ACM},
	organization = {ACM},
	author = {Pasquier, Thomas and Xueyuan Han and Goldstein, Mark and Moyer, Thomas and Eyers, David and Margo Seltzer and Bacon, Jean}
}

@proceedings{acsac,
  editor    = {Robert H'obbes' Zakon},
  title     = {28th Annual Computer Security Applications Conference, {ACSAC} 2012,
               Orlando, FL, USA, 3-7 December 2012},
  publisher = {{ACM}},
  year      = {2012},
  url       = {http://dl.acm.org/citation.cfm?id=2420950},
  isbn      = {978-1-4503-1312-4},
  timestamp = {Thu, 20 Dec 2012 09:02:24 +0100},
  biburl    = {http://dblp2.uni-trier.de/rec/bib/conf/acsac/2012},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@Article{Papadimitriou2010,
author="Papadimitriou, Panagiotis
and Dasdan, Ali
and Garcia-Molina, Hector",
title="Web graph similarity for anomaly detection",
journal="Journal of Internet Services and Applications",
year="2010",
month="May",
day="01",
volume="1",
number="1",
pages="19--30",
abstract="Web graphs are approximate snapshots of the web, created by search engines. They are essential to monitor the evolution of the web and to compute global properties like PageRank values of web pages. Their continuous monitoring requires a notion of graph similarity to help measure the amount and significance of changes in the evolving web. As a result, these measurements provide means to validate how well search engines acquire content from the web. In this paper, we propose five similarity schemes: three of them we adapted from existing graph similarity measures, and two we adapted from well-known document and vector similarity methods (namely, the shingling method and random projection based method). We empirically evaluate and compare all five schemes using a sequence of web graphs from Yahoo!, and study if the schemes can identify anomalies that may occur due to hardware or other problems.",
issn="1869-0238",
doi="10.1007/s13174-010-0003-x",
url="https://doi.org/10.1007/s13174-010-0003-x"
}

@inproceedings{Noble,
 author = {Noble, Caleb C. and Cook, Diane J.},
 title = {Graph-based Anomaly Detection},
 booktitle = {Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '03},
 year = {2003},
 isbn = {1-58113-737-0},
 location = {Washington, D.C.},
 pages = {631--636},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/956750.956831},
 doi = {10.1145/956750.956831},
 acmid = {956831},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {anomaly detection, data mining, graph regularity},
} 

@inproceedings{Muniswamy-Reddy,
 author = {Muniswamy-Reddy, Kiran-Kumar and Holland, David A. and Braun, Uri and Seltzer, Margo},
 title = {Provenance-aware Storage Systems},
 booktitle = {Proceedings of the Annual Conference on USENIX '06 Annual Technical Conference},
 series = {ATEC '06},
 year = {2006},
 location = {Boston, MA},
 pages = {4--4},
 numpages = {1},
 url = {http://dl.acm.org/citation.cfm?id=1267359.1267363},
 acmid = {1267363},
 publisher = {USENIX Association},
 address = {Berkeley, CA, USA},
} 
















